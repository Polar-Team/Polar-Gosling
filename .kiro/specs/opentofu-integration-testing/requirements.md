# Requirements Document: OpenTofu Integration Testing

## Introduction

This specification defines comprehensive integration testing for the OpenTofu configuration service in MotherGoose. The integration tests will validate the complete workflow from binary download through template generation, initialization, and plan storage using real infrastructure components (LocalStack for S3, YDB testcontainers).

## Glossary

- **OpenTofu**: Open-source infrastructure-as-code tool (Terraform fork)
- **LocalStack**: Local AWS cloud stack for testing
- **YDB**: Yandex Database for storing deployment plans
- **Testcontainer**: Docker containers for integration testing
- **HCL**: HashiCorp Configuration Language (Terraform/OpenTofu syntax)
- **S3_Backend**: S3-based state storage for OpenTofu
- **Deployment_Plan**: Binary plan file generated by OpenTofu

## Requirements

### Requirement 1: Binary Download and Validation

**User Story:** As a developer, I want to validate that OpenTofu binaries are correctly downloaded from GitHub, so that I can ensure the infrastructure deployment tool is authentic and functional.

#### Acceptance Criteria

1. WHEN the integration test runs, THE System SHALL download a real OpenTofu binary from GitHub releases
2. WHEN the binary is downloaded, THE System SHALL verify the SHA256 checksum matches the official release
3. WHEN the binary is validated, THE System SHALL confirm it is executable
4. WHEN the binary is executed with `--version`, THE System SHALL return a valid version string matching the expected format
5. THE System SHALL cache the downloaded binary for subsequent test runs to improve performance

### Requirement 2: Template Generation and Validation

**User Story:** As a developer, I want to validate that OpenTofu HCL templates are correctly generated from Jinja2 templates, so that I can ensure infrastructure configurations are syntactically correct.

#### Acceptance Criteria

1. WHEN templates are generated, THE System SHALL create valid `versions.tf` with provider constraints
2. WHEN templates are generated, THE System SHALL create valid S3 backend configuration
3. WHEN templates are generated, THE System SHALL include all required provider sources and versions
4. WHEN templates include health checks, THE System SHALL generate valid `checks.tf` configuration
5. THE System SHALL validate generated HCL syntax using `tofu fmt -check`
6. THE System SHALL validate generated HCL semantics using `tofu validate`

### Requirement 3: LocalStack S3 Backend Integration

**User Story:** As a developer, I want to test OpenTofu state management with LocalStack S3, so that I can validate backend configuration without using real AWS resources.

#### Acceptance Criteria

1. WHEN the integration test starts, THE System SHALL spin up a LocalStack testcontainer with S3 service
2. WHEN LocalStack is ready, THE System SHALL create the configured S3 bucket for state storage
3. WHEN LocalStack is ready, THE System SHALL create the configured DynamoDB table for state locking
4. WHEN OpenTofu initializes, THE System SHALL successfully connect to LocalStack S3 backend
5. WHEN OpenTofu runs, THE System SHALL store state files in LocalStack S3
6. WHEN the test completes, THE System SHALL clean up the LocalStack container

### Requirement 4: OpenTofu Initialization

**User Story:** As a developer, I want to validate OpenTofu initialization with real providers, so that I can ensure provider plugins are correctly downloaded and configured.

#### Acceptance Criteria

1. WHEN `tofu init` runs, THE System SHALL download required provider plugins
2. WHEN `tofu init` runs, THE System SHALL initialize the S3 backend successfully
3. WHEN `tofu init` runs, THE System SHALL create the `.terraform` directory structure
4. WHEN `tofu init` runs, THE System SHALL create the `.terraform.lock.hcl` file
5. WHEN initialization completes, THE System SHALL verify all providers are installed correctly
6. THE System SHALL cache provider plugins to S3 artifact cache for subsequent runs

### Requirement 5: Deployment Plan Generation

**User Story:** As a developer, I want to validate deployment plan generation, so that I can ensure OpenTofu correctly analyzes infrastructure changes.

#### Acceptance Criteria

1. WHEN `tofu plan` runs, THE System SHALL generate a binary plan file
2. WHEN the plan is generated, THE System SHALL return exit code 0 (no changes) or 2 (changes present)
3. WHEN the plan is generated, THE System SHALL produce valid binary plan data
4. WHEN the plan contains changes, THE System SHALL include resource additions, modifications, or deletions
5. THE System SHALL validate the plan file can be read back successfully

### Requirement 6: YDB Plan Storage Integration

**User Story:** As a developer, I want to test storing deployment plans in YDB, so that I can validate the complete deployment workflow including plan persistence.

#### Acceptance Criteria

1. WHEN the integration test starts, THE System SHALL spin up a YDB testcontainer
2. WHEN YDB is ready, THE System SHALL create required tables for plan storage
3. WHEN a deployment plan is generated, THE System SHALL store the binary plan in YDB
4. WHEN a plan is stored, THE System SHALL include metadata (egg_name, config_hash, git_commit, timestamp)
5. WHEN a plan is retrieved, THE System SHALL return the exact binary data that was stored
6. WHEN the test completes, THE System SHALL clean up the YDB container

### Requirement 7: Provider Plugin Caching

**User Story:** As a developer, I want to validate provider plugin caching to S3, so that I can ensure subsequent deployments are faster.

#### Acceptance Criteria

1. WHEN provider plugins are downloaded, THE System SHALL cache them to S3 artifact cache
2. WHEN plugins are cached, THE System SHALL organize them by provider source and version
3. WHEN a subsequent initialization runs, THE System SHALL restore plugins from cache
4. WHEN plugins are restored from cache, THE System SHALL skip downloading from provider registries
5. THE System SHALL verify cached plugins are functionally equivalent to freshly downloaded ones

### Requirement 8: End-to-End Workflow Validation

**User Story:** As a developer, I want to validate the complete OpenTofu workflow, so that I can ensure all components work together correctly.

#### Acceptance Criteria

1. WHEN the integration test runs, THE System SHALL execute the complete workflow: download → template generation → init → plan → store
2. WHEN the workflow completes, THE System SHALL verify each step succeeded
3. WHEN the workflow completes, THE System SHALL verify state is stored in S3
4. WHEN the workflow completes, THE System SHALL verify plan is stored in YDB
5. WHEN the workflow completes, THE System SHALL verify plugins are cached in S3
6. THE System SHALL complete the entire workflow within a reasonable timeout (5 minutes)

### Requirement 9: Error Handling and Recovery

**User Story:** As a developer, I want to validate error handling in the OpenTofu workflow, so that I can ensure failures are handled gracefully.

#### Acceptance Criteria

1. WHEN S3 backend is unavailable, THE System SHALL return a clear error message
2. WHEN provider download fails, THE System SHALL return a clear error message
3. WHEN template generation fails, THE System SHALL return a clear error message
4. WHEN plan generation fails, THE System SHALL return the OpenTofu error output
5. THE System SHALL clean up partial state when errors occur

### Requirement 10: Test Performance and Reliability

**User Story:** As a developer, I want integration tests to be reliable and reasonably fast, so that they can be run frequently in CI/CD pipelines.

#### Acceptance Criteria

1. WHEN integration tests run, THE System SHALL complete within 5 minutes
2. WHEN integration tests run multiple times, THE System SHALL produce consistent results
3. WHEN integration tests use caching, THE System SHALL reduce execution time by at least 50%
4. WHEN integration tests fail, THE System SHALL provide clear diagnostic information
5. THE System SHALL clean up all containers and resources after test completion

## Notes

- Integration tests should be marked with `@pytest.mark.integration` to allow selective execution
- Tests should use real OpenTofu binaries but mock actual infrastructure resources (use null provider or local provider)
- LocalStack and YDB containers should be session-scoped fixtures to improve test performance
- Binary and plugin caching should be implemented to avoid repeated downloads
- Tests should validate both success and failure scenarios
- Consider using OpenTofu's null provider or local provider for testing without creating real infrastructure
